{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "canadian-executive",
   "metadata": {},
   "source": [
    "# Particle Filter (PF) localisation : Comparing the localised PF from Farchi et al., (2018) (LPF) and the local PF with Inverse Distance Weighting PF (IDWPF) from Cantet et al. (2019)\n",
    "BC, Nov 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-enemy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T13:32:38.821315Z",
     "start_time": "2021-12-02T13:32:38.813353Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-stranger",
   "metadata": {},
   "source": [
    "## Example case\n",
    "\n",
    "Consider a case with two points 1 and 2 where we observe the change in the Height of Snow (HS, cm) after a precipitation event.\n",
    "\n",
    "We want to build an analysis for an unobserved point 3 located in the middle of the observed locations, using the LPF and the IDWPF.\n",
    "An ensemble of simulations is generated by perturbing the amount of HS change and the temperature from an initial (deterministic) simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-simon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T13:32:39.775233Z",
     "start_time": "2021-12-02T13:32:39.772117Z"
    }
   },
   "outputs": [],
   "source": [
    "## Model\n",
    "def hs_change(temp,precip):\n",
    "    '''\n",
    "    Our model hs_change(precip,temp) is fairly simple:\n",
    "     - if temp < 0 is negative: hs_change = precip (snowfall)\n",
    "     - else: hs_change = -0.2 * precip (rainfall induced settling)\n",
    "    '''\n",
    "    if temp <0:\n",
    "        return precip\n",
    "    else:\n",
    "        return -0.2 * precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-replication",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T13:32:40.213764Z",
     "start_time": "2021-12-02T13:32:40.188036Z"
    }
   },
   "outputs": [],
   "source": [
    "#### EXAMPLE PARAMETERS ####\n",
    "##  setting the parameters of the initial simulation.\n",
    "\n",
    "# Temperatures (Celsius)\n",
    "# Here, point 1 is way above the snow line, point 2 is close to the snow line. Point 3 is in between.\n",
    "base_temp = [-2, 0.25, -0.9]\n",
    "error_temp = 1  # additive error\n",
    "\n",
    "# Precips\n",
    "base_precip = [20, 20, 20] # identical precipitaiton amounts because points are close to each other.\n",
    "error_precip = 0.5 # multiplicative error of 50%.\n",
    "\n",
    "# HS changes from the initial deterministic simulation(cm)\n",
    "# Consistently with the temperature, it snows in both points, with i\n",
    "base_changes = [hs_change(T,p) for (p,T) in zip(base_precip, base_temp)]\n",
    "print('simulated HS changes from the initial simulation : ' + str(base_changes))\n",
    "nmembers = 1000\n",
    "\n",
    "## Observations\n",
    "\n",
    "# Observations are roughy consistent with the temperatures of the initial simulation.\n",
    "temp_obs = np.random.normal(0, error_temp) + np.array(base_temp)\n",
    "precip_obs = np.random.normal(1,error_precip) * np.array(base_precip)\n",
    "obs_all = [hs_change(T,p) for (p,T) in zip(precip_obs, temp_obs)]\n",
    "obs = obs_all[0:2]\n",
    "obs_verif =  obs_all[2]\n",
    "sigma = 2 # # a gaussian error of \\sigma cm is expected for each obs\n",
    "print('observed HS changes to be assimilated : ' + str(obs))\n",
    "print('observed HS changes to be used for verification: ' + str(obs_verif))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-ontario",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T13:32:40.683836Z",
     "start_time": "2021-12-02T13:32:40.642823Z"
    }
   },
   "outputs": [],
   "source": [
    "# #### ENSEMBLE ####\n",
    "\n",
    "pert_precip = np.random.normal(1, error_precip, nmembers)  # classical multiplicative perturbation for 'precipitation'\n",
    "pert_temp = np.random.normal(0,error_temp, nmembers)       # classical additive perturbation for 'temperature'\n",
    "ensemble_hs_change = np.array([[hs_change(base_temp[pt] + pert_temp[mb], base_precip[pt] * pert_precip[mb]) for mb in range(nmembers)] for pt in range(3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-disclosure",
   "metadata": {},
   "source": [
    "## Assimilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-trust",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T13:32:41.658919Z",
     "start_time": "2021-12-02T13:32:41.654113Z"
    }
   },
   "outputs": [],
   "source": [
    "def likelihood(obs, mb, sigma):\n",
    "    return np.exp(-0.5 * (obs - mb)**2/sigma**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-store",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T13:32:42.227980Z",
     "start_time": "2021-12-02T13:32:42.195991Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the weights acording to the LPF and the IDWPF.\n",
    "\n",
    "likelihoods = np.zeros((2, nmembers))\n",
    "initial_weights = np.ones((2,nmembers))/nmembers # particles have equal weights before assimilation (/!\\ plots and CRPS assume equal weights.)\n",
    "posterior_weights = np.zeros((2,nmembers))/nmembers # weights before normalization.\n",
    "\n",
    "## A. Compute the weights on pt1 and pt2 separately\n",
    "for pt in range(2):\n",
    "    for mb in range(nmembers):\n",
    "        likelihoods[pt,mb] = likelihood(obs[pt],ensemble_hs_change[pt,mb],sigma)\n",
    "        posterior_weights[pt,mb] = likelihoods[pt,mb] * initial_weights[pt,mb]\n",
    "        \n",
    "## B. LPF assimilation: \n",
    "# B.1. multiply the weights before normalization (Eq. 27 from Farchi and Bocquet, 2018)\n",
    "posterior_weights_all = np.prod(posterior_weights, axis=0)\n",
    "\n",
    "# B.2 normalize the LPF posterior weights\n",
    "posterior_weights_all = posterior_weights_all/np.sum(posterior_weights_all)\n",
    "\n",
    "\n",
    "# C IDWPF assimilation\n",
    "# C.1. normalize the posterior weights on pt1 and pt2\n",
    "for pt in range(2):\n",
    "    posterior_weights[pt,:] = posterior_weights[pt,:]/np.sum(posterior_weights[pt,:])\n",
    "\n",
    "# C.2 compute the Inverse distance weighting on pt3: average since pt3 is between pt1 and pt2\n",
    "posterior_weights_idw = np.mean(posterior_weights, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-screening",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T13:32:42.764687Z",
     "start_time": "2021-12-02T13:32:42.750337Z"
    }
   },
   "outputs": [],
   "source": [
    "def resampling(weights):\n",
    "    \"\"\"\n",
    "    PF resampling, Kitagawa (1996)\n",
    "    \"\"\"\n",
    "    nmembers = len(weights)\n",
    "    resample = np.empty(nmembers, dtype = int)\n",
    "    zweightcumul = np.cumsum(weights)\n",
    "    zrand = np.random.random() / nmembers\n",
    "    for ires in range(0, nmembers):\n",
    "        if zrand <= zweightcumul[0]:  # zweightcumul[0] = poids du mb 1\n",
    "            resample[ires] = 1\n",
    "        for rk in range(1, nmembers):\n",
    "            if (zweightcumul[rk - 1] < zrand) and (zrand <= zweightcumul[rk]):\n",
    "                resample[ires] = rk + 1\n",
    "\n",
    "        zrand += 1. / nmembers\n",
    "    return resample - 1    # -1 for python indexing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-visitor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T13:33:52.383112Z",
     "start_time": "2021-12-02T13:33:51.232226Z"
    }
   },
   "outputs": [],
   "source": [
    "res_all = resampling(posterior_weights_all)\n",
    "res_idw = resampling(posterior_weights_idw)\n",
    "res_pt = np.array([resampling(posterior_weights[pt,:]) for pt in range(2)])\n",
    "\n",
    "analysis_hs_change_all = np.transpose(np.array([ensemble_hs_change[:,sel] for i, sel in enumerate(res_all)]))\n",
    "analysis_hs_change_idw = np.transpose(np.array([ensemble_hs_change[:,sel] for i, sel in enumerate(res_idw)]))\n",
    "analysis_hs_change_pt = np.array([[ensemble_hs_change[pt,res_pt[pt,i]] for i in range(nmembers)] for pt in range(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-spirituality",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-wisdom",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T13:33:53.691946Z",
     "start_time": "2021-12-02T13:33:53.685610Z"
    }
   },
   "outputs": [],
   "source": [
    "def CRPS(ensemble, obs):\n",
    "\n",
    "    obsCDF = 0\n",
    "    ensembleCDF = 0\n",
    "    precPrevision = 0\n",
    "    integrale = 0\n",
    "    ensemble = np.sort(ensemble)\n",
    "    for prevision in ensemble:\n",
    "        # immediately after obs\n",
    "        if obsCDF == 0 and obs < prevision:\n",
    "            integrale += (obs - precPrevision) * (ensembleCDF ** 2)\n",
    "            integrale += (prevision - obs) * (ensembleCDF - 1) ** 2\n",
    "            obsCDF = 1.\n",
    "        # otherwise\n",
    "        else:\n",
    "            integrale += ((prevision - precPrevision) * (ensembleCDF - obsCDF) ** 2)\n",
    "        ensembleCDF += 1. / len(ensemble)\n",
    "        precPrevision = prevision\n",
    "\n",
    "    # if obs > all forecasts\n",
    "    if obsCDF == 0:\n",
    "        integrale += obs - prevision\n",
    "\n",
    "    CRPS = integrale\n",
    "    return CRPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-pound",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T13:33:54.520081Z",
     "start_time": "2021-12-02T13:33:54.388245Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "xmin = -20\n",
    "xmax = 40\n",
    "bins = np.arange(xmin,xmax,2)\n",
    "fig, axs = plt.subplots(ncols =3, sharey = True, figsize = (10,4))\n",
    "for pt in range(3):\n",
    "    ax = axs[pt]\n",
    "    ax.plot(bins, likelihood(obs[pt] if pt<2 else obs_verif, bins,sigma)/4, color = 'r',label = 'obs')\n",
    "\n",
    "    ax.hist(ensemble_hs_change[pt,:], histtype = 'step', lw  = 2,density = True,bins = bins, label = 'prior')\n",
    "    #ax.hist(analysis_hs_change_pt[pt,:], histtype = 'step', lw  = 1, density = True,bins = bins,label = 'analysis_pt', color = 'k')\n",
    "    ax.hist(analysis_hs_change_all[pt,:], histtype = 'step', lw  = 2, density = True,bins = bins,label = 'analysis_all')\n",
    "    ax.hist(analysis_hs_change_idw[pt,:], histtype = 'step', lw  = 2, density = True,bins = bins,label = 'analysis_idw')\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_xlabel('hs change (cm) point ' + str(pt+1))\n",
    "_ = axs[0].set_ylabel('pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-bread",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T13:32:47.857528Z",
     "start_time": "2021-12-02T13:32:47.850566Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('CRPS on pt3 before assimilation (cm):     ' + str(CRPS(ensemble_hs_change[2,:],obs_verif)))\n",
    "print('CRPS on pt3 with LPF assimilation (cm):   ' + str(CRPS(analysis_hs_change_all[2,:],obs_verif)))\n",
    "print('CRPS on pt3 with IDWPF assimilation (cm): ' + str(CRPS(analysis_hs_change_idw[2,:],obs_verif)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-address",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
